{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd60381d-6763-4770-83a9-20f29e76e7bf",
   "metadata": {},
   "source": [
    "# ML Graphs (with mlflow)\n",
    "\n",
    "Flypipe allows creation of graphs to train ML models and run predictions.\n",
    "\n",
    "Here as example, we are building the following graph to train, evaluate and predict.\n",
    "\n",
    "![ML Graph](ml.png)\n",
    "\n",
    "\n",
    "The graph above contains the following nodes:\n",
    "\n",
    "**Training Graph**\n",
    "\n",
    "- **data**: loads sklearn iris dataset into a dataframe\n",
    "- **split**: splits the data into train/test data\n",
    "- **fit_scale**: fit and scale the data using sklearn Standard Scaler\n",
    "- **train_svm_model**: trains a sklearn SVM model on train data and returns the prediction\n",
    "- **evaluate**: calculates evaluation metrics\n",
    "\n",
    "\n",
    "**Prediction Graph**\n",
    "\n",
    "- **scale**: scales the data using the scaler fit on node `fit_scale`\n",
    "- **predict**: loads the SVM model trained in the node `train_svm_model` and does the predictions\n",
    "\n",
    "\n",
    "**Governance**\n",
    "\n",
    "- **graph**: dummy node used to plot all related graphs to the model\n",
    "\n",
    "> In this section, we are using [mlflow](https://mlflow.org/docs/latest/index.html) to save and loand ML artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92f5e4a-d2da-4797-9122-0076998e9f15",
   "metadata": {},
   "source": [
    "## Training Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ed60cc-b5ee-4cc1-b134-f883488be51f",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b9da36-2d0f-4a6f-9adf-96bad0687cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flypipe import node\n",
    "from flypipe.schema import Schema, Column\n",
    "from flypipe.schema.types import Float, Integer\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "\n",
    "\n",
    "@node(\n",
    "    type=\"pandas\",\n",
    "    description=\"Load Iris dataset\",\n",
    "    tags=[\"data\"],\n",
    "    output=Schema(\n",
    "      Column('sepal_length', Float(), 'sepal length'),  \n",
    "      Column('sepal_width', Float(), 'sepal width'),  \n",
    "      Column('petal_length', Float(), 'petal length'),  \n",
    "      Column('petal_width', Float(), 'petal width'),  \n",
    "      Column('target', Integer(), '0: Setosa, 1: Versicolour, and 2: Virginica'),\n",
    "    ))\n",
    "def data():\n",
    "    iris = datasets.load_iris()\n",
    "    df = pd.DataFrame(data = {\n",
    "        'sepal_length': iris.data[:,0],\n",
    "        'sepal_width': iris.data[:,1],\n",
    "        'petal_length': iris.data[:,2],\n",
    "        'petal_width': iris.data[:,3],\n",
    "        'target': iris.target\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "    \n",
    "data.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a110e225-b0c1-4487-830b-8fe1da9922f9",
   "metadata": {},
   "source": [
    "### Split data as train (70%) and test (30%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f42ea20-042c-457d-af33-8703705046c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flypipe import node\n",
    "from flypipe.schema import Schema, Column\n",
    "from flypipe.schema.types import Float, String\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "@node(\n",
    "    type=\"pandas\",\n",
    "    description=\"Split train (70%) and test (30%) data\",\n",
    "    tags=[\"data\", \"split\"],\n",
    "    dependencies=[\n",
    "        data.select(\n",
    "            'sepal_length',\n",
    "            'sepal_width',\n",
    "            'petal_length',\n",
    "            'petal_width',\n",
    "            'target',\n",
    "        )\n",
    "    ],\n",
    "    output=Schema(\n",
    "      Column('data_type', String(), 'train (70%), test (30%)'),  \n",
    "      data.output.get(\"sepal_length\"),\n",
    "      data.output.get(\"sepal_width\"),\n",
    "      data.output.get(\"petal_length\"),\n",
    "      data.output.get(\"petal_width\"),\n",
    "      data.output.get(\"target\"),\n",
    "      \n",
    "    ))\n",
    "def split(data):\n",
    "    data['data_type'] = \"train\"\n",
    "    \n",
    "    X_cols = [\n",
    "        'sepal_length',\n",
    "        'sepal_width',\n",
    "        'petal_length',\n",
    "        'petal_width'\n",
    "    ]\n",
    "    y_col = 'target'\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(data[X_cols], \n",
    "                                                        data[y_col], \n",
    "                                                        test_size=0.3, \n",
    "                                                        random_state=1)\n",
    "\n",
    "    X_train['data_type'] = 'train'\n",
    "    X_train['target'] = y_train\n",
    "    \n",
    "    X_test['data_type'] = 'test'\n",
    "    X_test['target'] = y_test\n",
    "    \n",
    "    data = pd.concat([X_train, X_test])\n",
    "    return data\n",
    "    \n",
    "df = split.run()\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1344a7-d365-4cad-8024-e770022ad3ae",
   "metadata": {},
   "source": [
    "### Fit and Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc77dc64-393d-4343-b4d4-f455b22e298a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "ARTIFACT_LOCATION = \"/data/tmp/artifacts/\"\n",
    "os.makedirs(ARTIFACT_LOCATION, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed39b16e-ecfd-43eb-9f55-90c09ccba298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle \n",
    "import mlflow\n",
    "\n",
    "from flypipe import node\n",
    "from flypipe.schema import Schema, Column\n",
    "from flypipe.schema.types import Float, String\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "@node(\n",
    "    type=\"pandas\",\n",
    "    description=\"Fits a standard scaler\",\n",
    "    tags=[\"data\", \"train\", \"scaler\"],\n",
    "    dependencies=[\n",
    "        split.select(\n",
    "            'data_type',\n",
    "            'sepal_length',\n",
    "            'sepal_width',\n",
    "            'petal_length',\n",
    "            'petal_width',\n",
    "            'target',\n",
    "        )\n",
    "    ],\n",
    "    output=Schema(\n",
    "      Column('data_type', String(), 'train (70%), test (30%)'),  \n",
    "      split.output.get(\"sepal_length\"),\n",
    "      split.output.get(\"sepal_width\"),\n",
    "      split.output.get(\"petal_length\"),\n",
    "      split.output.get(\"petal_width\"),\n",
    "      split.output.get(\"target\"),      \n",
    "    ))    \n",
    "def fit_scale(split):\n",
    "    \n",
    "    X_cols = [\n",
    "        'sepal_length',\n",
    "        'sepal_width',\n",
    "        'petal_length',\n",
    "        'petal_width'\n",
    "    ]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler = scaler.fit(split[split['data_type']=='train'][X_cols])\n",
    "    \n",
    "    if mlflow.active_run():\n",
    "        artifact_path = f\"{ARTIFACT_LOCATION}{mlflow.active_run().info.run_id}/model\"\n",
    "        if not os.path.exists(artifact_path):\n",
    "            os.makedirs(artifact_path, exist_ok=True)\n",
    "\n",
    "        pickle.dump(scaler, open(os.path.join(artifact_path, 'scaler.pkl'), 'wb'))\n",
    "    \n",
    "    split[X_cols] = scaler.transform(split[X_cols])\n",
    "    \n",
    "    return split\n",
    "    \n",
    "df = fit_scale.run()\n",
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4553aead-4c2a-43ed-90ac-b92b3a0d48d1",
   "metadata": {},
   "source": [
    "### Train SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd66903-ec64-46b8-a2a8-0a9f120f483f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flypipe import node\n",
    "from flypipe.schema import Schema, Column\n",
    "from flypipe.schema.types import Float, String, Integer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "@node(\n",
    "    type=\"pandas\",\n",
    "    description=\"Model training using SVM\",\n",
    "    tags=[\"model\", \"svm\"],\n",
    "    dependencies=[\n",
    "        fit_scale.select(\n",
    "            'data_type',\n",
    "            'sepal_length',\n",
    "            'sepal_width',\n",
    "            'petal_length',\n",
    "            'petal_width',\n",
    "            'target',\n",
    "        ).alias(\"df\")\n",
    "    ],\n",
    "    output=Schema(\n",
    "      Column('data_type', String(), 'train (70%), test (30%)'),  \n",
    "      fit_scale.output.get(\"sepal_length\"),\n",
    "      fit_scale.output.get(\"sepal_width\"),\n",
    "      fit_scale.output.get(\"petal_length\"),\n",
    "      fit_scale.output.get(\"petal_width\"),\n",
    "      fit_scale.output.get(\"target\"),      \n",
    "      Column('prediction', Integer(), 'prediction'),  \n",
    "    ))\n",
    "def train_svm_model(df):\n",
    "    \n",
    "    X_cols = [\n",
    "        'sepal_length',\n",
    "        'sepal_width',\n",
    "        'petal_length',\n",
    "        'petal_width'\n",
    "    ]\n",
    "    \n",
    "    X_train = df[df['data_type']=='train']\n",
    "    y_train = X_train['target']\n",
    "    X_train = X_train[X_cols]\n",
    "    \n",
    "    clf = svm.SVC().fit(X_train, y_train)\n",
    "        \n",
    "    if mlflow.active_run():\n",
    "        signature = infer_signature(X_train, y_train)\n",
    "        mlflow.sklearn.log_model(clf, \n",
    "                                 \"model\", \n",
    "                                 signature=signature, \n",
    "                                 input_example=X_train.head(5))\n",
    "  \n",
    "\n",
    "    df['prediction'] = clf.predict(df[X_cols])\n",
    "    return df\n",
    "    \n",
    "df = train_svm_model.run()\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26857b0-526e-4b06-ba13-ba08be97b589",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5cbcf8-4d65-4156-947d-c06c97a68d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flypipe import node\n",
    "from flypipe.schema import Schema, Column\n",
    "from flypipe.schema.types import Float, String, Integer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from mlflow.models.signature import infer_signature\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "@node(\n",
    "    type=\"pandas\",\n",
    "    description=\"Model training using SVM\",\n",
    "    tags=[\"model\", \"svm\"],\n",
    "    dependencies=[\n",
    "        train_svm_model.select(\n",
    "            'data_type',\n",
    "            'target',\n",
    "            'prediction'\n",
    "        ).alias(\"df\")\n",
    "    ],\n",
    "    output=Schema(\n",
    "      Column('data_type', String(), 'all, train or test'),  \n",
    "      Column('metric', String(), 'score metric'),  \n",
    "      Column('value', Float(), 'value of the metric'),        \n",
    "    ))\n",
    "def evaluate(df):\n",
    "    result = pd.DataFrame(columns=['data_type', 'metric', 'value'])\n",
    "    \n",
    "    # All data\n",
    "    score = f1_score(df['target'], df['prediction'], average='macro')\n",
    "    result.loc[result.shape[0]] = ['all', 'f1_score macro', score]\n",
    "    \n",
    "    # Train data\n",
    "    df_ = df[df['data_type']=='train']\n",
    "    score = f1_score(df_['target'], df_['prediction'], average='macro')\n",
    "    result.loc[result.shape[0]] = ['train', 'f1_score macro', score]\n",
    "    \n",
    "    # Test data\n",
    "    df_ = df[df['data_type']=='test']\n",
    "    score = f1_score(df_['target'], df_['prediction'], average='macro')\n",
    "    result.loc[result.shape[0]] = ['test', 'f1_score macro', score]\n",
    "    \n",
    "    return result\n",
    "    \n",
    "df = evaluate.run()\n",
    "display(df)\n",
    "\n",
    "displayHTML(evaluate.html())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f1e1c8-4fd6-41c1-b2d4-92cdaad1dc1b",
   "metadata": {},
   "source": [
    "### Executing Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f56dd1-496a-4b4e-8413-3b61599312fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "from mlflow import log_metric, log_param, log_artifacts\n",
    "from mlflow.exceptions import MlflowException\n",
    "\n",
    "\n",
    "# Ends any actve mlflow run\n",
    "try:\n",
    "    mlflow.end_run()\n",
    "except Exception as e:\n",
    "    pass\n",
    "\n",
    "\"\"\"\n",
    "Creates or gets an experiment from /Shared folder\n",
    "Sets the artifact location to the mounted blob\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    experiment_id = mlflow.create_experiment('flypipe_demo', artifact_location=ARTIFACT_LOCATION)\n",
    "except MlflowException as m:\n",
    "    pass\n",
    "finally:\n",
    "    experiment = mlflow.get_experiment_by_name('flypipe_demo')\n",
    "    experiment_id = experiment.experiment_id\n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "Starts the mlflow run with the experiment\n",
    "\"\"\"    \n",
    "mlflow.start_run(experiment_id=experiment_id) \n",
    "RUN_ID = mlflow.active_run().info.run_id\n",
    "print(f\"Training run_id: {RUN_ID}\")\n",
    "\n",
    "df = evaluate.run()\n",
    "\n",
    "display(df)\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9595684-c1ea-4fdc-9960-1a7237e8f37a",
   "metadata": {},
   "source": [
    "## Prediction Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e83c3ef-be4a-46a9-add1-36b213edd031",
   "metadata": {},
   "source": [
    "### Scale data for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dedc6c-cbdc-4345-94cb-5a40fe12d0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flypipe import node\n",
    "from flypipe.schema import Schema, Column\n",
    "from flypipe.schema.types import Float, String\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "@node(\n",
    "    type=\"pandas\",\n",
    "    description=\"Split train (70%) and test (30%) data\",\n",
    "    tags=[\"data\", \"split\"],\n",
    "    dependencies=[\n",
    "        data.select(\n",
    "            'sepal_length',\n",
    "            'sepal_width',\n",
    "            'petal_length',\n",
    "            'petal_width',\n",
    "        )\n",
    "    ],\n",
    "    output=Schema(\n",
    "      data.output.get(\"sepal_length\"),\n",
    "      data.output.get(\"sepal_width\"),\n",
    "      data.output.get(\"petal_length\"),\n",
    "      data.output.get(\"petal_width\"),\n",
    "    ))\n",
    "def scale(data):\n",
    "    \n",
    "    X_cols = [\n",
    "        'sepal_length',\n",
    "        'sepal_width',\n",
    "        'petal_length',\n",
    "        'petal_width'\n",
    "    ]\n",
    "    \n",
    "    with open(f'{ARTIFACT_LOCATION}{RUN_ID}/model/scaler.pkl', 'rb') as fp:\n",
    "        scaler = pickle.load(fp)\n",
    "        data[X_cols] = scaler.transform(data[X_cols])\n",
    "        \n",
    "    return data\n",
    "\n",
    "df = scale.run()\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3d9e5f-c004-44ef-9df7-b89f67426b0e",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5184b5-c169-4372-ab18-5a09b5c527b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flypipe import node\n",
    "from flypipe.schema import Schema, Column\n",
    "from flypipe.schema.types import Float, String\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "@node(\n",
    "    type=\"pandas\",\n",
    "    description=\"Split train (70%) and test (30%) data\",\n",
    "    tags=[\"data\", \"split\"],\n",
    "    dependencies=[\n",
    "        scale.select(\n",
    "            'sepal_length',\n",
    "            'sepal_width',\n",
    "            'petal_length',\n",
    "            'petal_width'\n",
    "        ).alias(\"df\")\n",
    "    ],\n",
    "    output=Schema(\n",
    "      Column('prediction', Integer(), 'prediction'),  \n",
    "      \n",
    "    ))\n",
    "def predict(df):\n",
    "    model_path = f'runs:/{RUN_ID}/model'\n",
    "    loaded_model = mlflow.pyfunc.load_model(model_path)\n",
    "\n",
    "    df['prediction'] = loaded_model.predict(df)\n",
    "    return df\n",
    "\n",
    "df = predict.run()\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab219ed3-da4f-408a-a37c-3f6164633fcf",
   "metadata": {},
   "source": [
    "## Document Training and Prediction Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b354d534-60f2-4ae5-88c8-1fbfd7334ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@node(\n",
    "    type=\"pandas\",\n",
    "    description=\"Graph to train and predict Iris Data set\",\n",
    "    dependencies=[\n",
    "        evaluate,\n",
    "        predict\n",
    "    ])\n",
    "def graph(evaluate, predict):\n",
    "    raise NotImplemented('Not supposed to run, only used to display the graph')\n",
    "    \n",
    "displayHTML(graph.html())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc92fbb-97b6-448c-aecb-f56ef4eb2cb8",
   "metadata": {},
   "source": [
    "## Run predictions with provided data\n",
    "\n",
    "We can make use of `inputs` when running the node `predict`.\n",
    "It allow us to give a custom data to be scaled and retrieve the predictions.\n",
    "\n",
    "This feature is useful when making analysis or using the same pipeline in other environments like APIs (discussed later on).\n",
    "\n",
    "Here we are giving 1 example of sepal and petal lenght and widths. Note that the execution graph will **skip** `data` node and use the data we are providing as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796818ba-ce26-4843-9f80-d43631960496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hard coded data to be predicted\n",
    "df = pd.DataFrame(data = {\n",
    "        'sepal_length': [6.6],\n",
    "        'sepal_width': [3.1],\n",
    "        'petal_length': [5.1],\n",
    "        'petal_width': [2.4]\n",
    "    })\n",
    "\n",
    "# Run the predictions\n",
    "predictions = (\n",
    "    predict\n",
    "    .run(inputs={\n",
    "        data: df\n",
    "    })\n",
    ")\n",
    "\n",
    "# Show predictions\n",
    "display(predictions)\n",
    "\n",
    "# How the execution graph\n",
    "displayHTML(\n",
    "    predict\n",
    "    .html(inputs={\n",
    "        data: df\n",
    "    })\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
