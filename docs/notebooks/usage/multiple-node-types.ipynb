{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d12cf88-3ba0-4686-ae9f-08f47d073e50",
   "metadata": {},
   "source": [
    "## Multi Node Type Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7c8c16-c3b3-4ff4-813b-45615a01e911",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dummy raw data\n",
    "\n",
    "df = spark.createDataFrame(\n",
    "    schema=(\"_fruit\",),\n",
    "    data=[\n",
    "        (\"ORANGE\",),\n",
    "        (\"WATERMELON\",),\n",
    "        (\"LEMON\",),\n",
    "    ]\n",
    ")\n",
    "df.createOrReplaceTempView(\"table\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c4c63b-d263-4dc6-972b-2fee18cf432e",
   "metadata": {},
   "source": [
    "### adding `pyspark` node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823b8223-f949-46f5-ac31-29b61e589ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flypipe.node import node\n",
    "from flypipe.datasource.spark import Spark\n",
    "from flypipe.schema import Schema, Column\n",
    "from flypipe.schema.types import String\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "@node(\n",
    "    type=\"pyspark\",\n",
    "    dependencies=[\n",
    "        Spark(\"table\").select(\"_fruit\").alias(\"df\")\n",
    "    ],\n",
    "    output=Schema(\n",
    "     Column(\"fruit\", String(), \"fruit description\"),\n",
    "    )\n",
    ")\n",
    "def rename_clean(df):\n",
    "    df = df.withColumnRenamed('_fruit', 'fruit')\n",
    "    df = df.withColumn('fruit', F.lower(F.col('fruit')))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b1028f-5380-4c6b-b043-c9589e59156e",
   "metadata": {},
   "source": [
    "#### running a `pyspark` node\n",
    "\n",
    "It wil node require `spark` session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ebb829-247a-4a6c-9032-d2dc969e6696",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_clean.run(spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6781d5dd-5ad3-468a-9f98-a49a6dedd221",
   "metadata": {},
   "source": [
    "### adding `pandas_on_spark` node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c1823c-86f3-4edf-ad4e-0d98d0b962e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@node(\n",
    "    type=\"pandas_on_spark\",\n",
    "    dependencies=[\n",
    "       rename_clean.select(\"fruit\").alias(\"df\")\n",
    "    ],\n",
    "    output=Schema(\n",
    "        rename_clean.output.get(\"fruit\"),\n",
    "        Column(\"category\", String(), \"category of the fruit\"),\n",
    "    )\n",
    ")\n",
    "def category(df):\n",
    "\n",
    "    replacements = {\n",
    "        \"orange\": \"citric\",\n",
    "        \"watermelon\": \"sweet\",\n",
    "        \"lemon\": \"citric\",\n",
    "    }\n",
    "    \n",
    "    df['category'] = df['fruit']\n",
    "    df = df.replace({'category': replacements})\n",
    "    return df\n",
    "\n",
    "\n",
    "@node(\n",
    "    type=\"pandas_on_spark\",\n",
    "    dependencies=[\n",
    "       rename_clean.select(\"fruit\").alias(\"df\")\n",
    "    ],\n",
    "    output=Schema(\n",
    "        rename_clean.output.get(\"fruit\"),\n",
    "        Column(\"color\", String(), \"color of the fruit\"),\n",
    "    )\n",
    ")\n",
    "def color(df):\n",
    "    replacements = {\n",
    "        \"orange\": \"orange\",\n",
    "        \"watermelon\": \"red\",\n",
    "        \"lemon\": \"yellow\",\n",
    "    }\n",
    "    df['color'] = df['fruit']\n",
    "    df = df.replace({'color': replacements})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafc6433-6467-4678-84e6-c727b962a011",
   "metadata": {},
   "source": [
    "#### running a `pandas_on_spark` node\n",
    "Because your graph is dependent on spark operations, it will also require a `spark` session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11996ed-fedc-406e-ab24-6f54cd295149",
   "metadata": {},
   "outputs": [],
   "source": [
    "color.run(spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf78d22-7643-4227-b704-0ec89e746e6f",
   "metadata": {},
   "source": [
    "### adding `pandas` node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ecc980-21ae-44a1-9656-5e2e59bddf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@node(\n",
    "    type=\"pandas\",\n",
    "    dependencies=[\n",
    "       color.select(\"fruit\", \"color\"),\n",
    "       category.select(\"fruit\", \"category\")\n",
    "    ],\n",
    "    output=Schema(\n",
    "        color.output.get(\"fruit\"),\n",
    "        color.output.get(\"color\"),\n",
    "        category.output.get(\"category\"),\n",
    "    )\n",
    ")\n",
    "def fruits(color, category):\n",
    "    return color.merge(category, on=\"fruit\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a59fbc-e3e0-4433-8037-3acece329ed5",
   "metadata": {},
   "source": [
    "#### running a `pandas` node\n",
    "Because your graph is dependent on spark operations, it will also require a `spark` session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343c7473-81df-4411-8e39-e0afd3cee3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruits.run(spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e630b6-c5e3-423f-9be2-f4148b37d1c1",
   "metadata": {},
   "source": [
    "### Putting all together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c00ac07-7993-4bf2-ba37-6a7aaa154dfc",
   "metadata": {},
   "source": [
    "The code above created a graph with 3 types of nodes\n",
    "\n",
    "* table: `pyspark` node\n",
    "* clean: `pandas_on_spark` node\n",
    "* color: `pandas_on_spark` node\n",
    "* category: `pandas` node\n",
    "\n",
    "As showed in the graph bellow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb452ca2-a4b3-4083-a331-31229432e141",
   "metadata": {},
   "outputs": [],
   "source": [
    "displayHTML(fruits.html())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3ca9c9-eea8-4125-966a-af7fdb880567",
   "metadata": {},
   "source": [
    "When running this graph the following processes will be executed:\n",
    "\n",
    "1. spark will query the table and select the columns specified in node `table`\n",
    "2. before running node `rename_clean`, flypipe will convert the ouput *pyspark* dataframe from node `table` to a *pandas_on_spark* dataframe\n",
    "3. node `rename_clean` is processed\n",
    "4. nodes `color` and `category` will be processed using the output *pandas_on_spark* dataframe output by node `rename_clean`\n",
    "5. once nodes `color` and `category` are processed, each dataframe is converted to `pandas` dataframe as node `fruits` is of the type *pandas*\n",
    "6. node `fruits` is processed and its dataframe output is returned\n",
    "\n",
    "Flypipe managages all these sequences and transformations for the user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf85a420-d948-4579-a02f-927647a5be88",
   "metadata": {},
   "source": [
    "### Advantages of mixed node types pipelines\n",
    "\n",
    "* end-to-end unification of different teams pipelines (data -> feture engineering -> modelling -> inference -> ...) [^1]\n",
    "* can lead to much faster results if running nodes `pandas_on_spark` as `pandas`\n",
    "* same pipeline can be used within APIs to run on the fly transformations\n",
    "\n",
    "[^1]: Different teams can use different syntaxes, i.e. `pyspark` is commnly used by data engineers, and `pandas` is commonly used by machine learning and data science teams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4c82fc-bd69-4d87-9dcc-de30b5fb9396",
   "metadata": {},
   "source": [
    "## Different ways of running a graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a830ef5-c20a-4a96-aaed-1c1d8c12b601",
   "metadata": {},
   "source": [
    "### 1. Default (as implemented)\n",
    "\n",
    "> Tip: `spark` is not required if your graph executes only `pandas` nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0325d2a8-f457-4dc1-97e2-9601a513b423",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fruits.run(spark)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88379c4e-d9da-407a-82f7-542125750ea1",
   "metadata": {},
   "source": [
    "### 2. Providing an existent `pyspark` dataframe as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89cdc66-abb1-4911-b773-01fc3ee77bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_table_df = spark.createDataFrame(data=[(\"ORANGE\",), (\"WATERMELON\",), (\"LEMON\",),], schema=[\"_fruit\"])\n",
    "\n",
    "df = fruits.run(inputs={ Spark(\"table\"): fruit_table_df })\n",
    "display(df)\n",
    "\n",
    "displayHTML(fruits.html(inputs={ Spark(\"table\"): fruit_table_df }))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b0c66d-cdd1-401c-ac60-234ea88f4273",
   "metadata": {},
   "source": [
    "> Note: as `table` node has been provided as input, the execution of node `table` is `skipped` and the provided input is used to calculated its predecessors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba18a06-10db-45a4-9af9-f0e8d7a29839",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3. Providing `pandas` dataframe as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f040e0f-4c77-4893-aff0-384bfcd3a13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "fruit_table_df = pd.DataFrame(data={\"_fruit\": [\"ORANGE\", \"WATERMELON\", \"LEMON\"]})\n",
    "\n",
    "df = fruits.run(spark, inputs={ Spark(\"table\"): fruit_table_df })\n",
    "display(df)\n",
    "\n",
    "displayHTML(fruits.html(inputs={ Spark(\"table\"): fruit_table_df }))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b212e7-c825-4fd8-9bf1-b8e6e226339c",
   "metadata": {},
   "source": [
    "> Note: even though `table` node is of type `pyspark` and the provided input is of type Pandas, Flypipe will convert it to the appropriate node type down the graph execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9391477-1649-4fdf-b2fe-e773d6460ae6",
   "metadata": {},
   "source": [
    "### 4. `pandas_on_spark` nodes as `pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64eca480-75a5-4a53-a109-d17b83e11d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fruits.run(spark, pandas_on_spark_use_pandas=True)\n",
    "display(df)\n",
    "\n",
    "displayHTML(fruits.html(pandas_on_spark_use_pandas=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6775020f-ff70-4c3c-bf80-c169349bcf31",
   "metadata": {},
   "source": [
    "### 5. `pandas_on_spark` nodes as `pandas` + provided `pyspark` dataframe as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d65c88-23d5-4d91-96f9-a593cb53cb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_table_df = spark.createDataFrame(pd.DataFrame(data={\"_fruit\": [\"ORANGE\", \"WATERMELON\", \"LEMON\"]}))\n",
    "\n",
    "df = fruits.run(pandas_on_spark_use_pandas=True, inputs={ Spark(\"table\"): fruit_table_df })\n",
    "display(df)\n",
    "\n",
    "displayHTML(fruits.html(inputs={ Spark(\"table\"): fruit_table_df }, pandas_on_spark_use_pandas=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2836670-7ecd-4383-bae0-dacf819e3d5a",
   "metadata": {},
   "source": [
    "### 6. `pandas_on_spark` nodes as `pandas` + provided `pandas` dataframe as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e1d0a5-78c6-41e4-882c-c00542c9984b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_clean_df = pd.DataFrame(data={\"fruit\": [\"orange\", \"watermelon\", \"lemon\"]})\n",
    "\n",
    "df = fruits.run( \n",
    "    pandas_on_spark_use_pandas=True, \n",
    "    inputs={ \n",
    "        rename_clean: rename_clean_df \n",
    "    })\n",
    "\n",
    "display(df)\n",
    "\n",
    "displayHTML(fruits.html(inputs={ rename_clean: rename_clean_df }, pandas_on_spark_use_pandas=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c1f8a3-6a2a-4671-b184-396ce84154db",
   "metadata": {},
   "source": [
    "### Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4c1164-6d1c-41bf-bac7-01b8d30231e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from textwrap import wrap\n",
    "\n",
    "results = pd.DataFrame(columns=['experiment', 'running_time_ms'])\n",
    "\n",
    "experiment = \"1. Default (as implemented)\"\n",
    "print(experiment)\n",
    "result = %timeit -o fruits.run(spark)\n",
    "results.loc[results.shape[0]] = [experiment, result.average]\n",
    "\n",
    "experiment = \"2. Providing an existent `pyspark` dataframe as input\"\n",
    "print(experiment)\n",
    "fruit_table_df = spark.createDataFrame(pd.DataFrame(data={\"_fruit\": [\"ORANGE\", \"WATERMELON\", \"LEMON\"]}))\n",
    "result = %timeit -o fruits.run(inputs={ Spark(\"table\"): fruit_table_df })\n",
    "results.loc[results.shape[0]] = [experiment, result.average]\n",
    "\n",
    "experiment = \"3. Providing `pandas` dataframe as input\"\n",
    "print(experiment)\n",
    "fruit_table_df = pd.DataFrame(data={\"_fruit\": [\"ORANGE\", \"WATERMELON\", \"LEMON\"]})\n",
    "result = %timeit -o fruits.run(spark, inputs={ Spark(\"table\"): fruit_table_df })\n",
    "results.loc[results.shape[0]] = [experiment, result.average]\n",
    "\n",
    "experiment = \"4. `pandas_on_spark` nodes as `pandas`\"\n",
    "print(experiment)\n",
    "result = %timeit -o fruits.run(spark, pandas_on_spark_use_pandas=True)\n",
    "results.loc[results.shape[0]] = [experiment, result.average]\n",
    "\n",
    "experiment = \"5. `pandas_on_spark` nodes as `pandas` + provided `pyspark` dataframe as input\"\n",
    "print(experiment)\n",
    "fruit_table_df = spark.createDataFrame(pd.DataFrame(data={\"_fruit\": [\"ORANGE\", \"WATERMELON\", \"LEMON\"]}))\n",
    "result = %timeit -o fruits.run(pandas_on_spark_use_pandas=True, inputs={ Spark(\"table\"): fruit_table_df })\n",
    "results.loc[results.shape[0]] = [experiment, result.average]\n",
    "\n",
    "experiment = \"6. `pandas_on_spark` nodes as `pandas` + provided `pandas` dataframe as input\"\n",
    "print(experiment)\n",
    "rename_clean_df = pd.DataFrame(data={\"fruit\": [\"orange\", \"watermelon\", \"lemon\"]})\n",
    "result = %timeit -o fruits.run(pandas_on_spark_use_pandas=True, inputs={ rename_clean: rename_clean_df })\n",
    "results.loc[results.shape[0]] = [experiment, result.average]\n",
    "\n",
    "results['experiment'] = results['experiment'].apply(lambda x: '\\n'.join(wrap(x, 20)))\n",
    "results['running_time_ms'] = results['running_time_ms'] * 1000\n",
    "results['running_time_ms'] = round(results['running_time_ms'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11dcf62-a1bd-4a01-809d-f37a277d4b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 4))\n",
    "pal = sns.color_palette(\"Blues_d\", len(results))\n",
    "barchart = (\n",
    "    sns.barplot(x=results['experiment'], \n",
    "                y=results['running_time_ms'], \n",
    "                palette=np.array(pal[::-1]),\n",
    "                ax=ax)\n",
    "                .set(title='Running time (ms) by different ways of running the graph')\n",
    ")\n",
    "\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fmt='%.1f ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818f251d-a989-4921-872e-1f3098628551",
   "metadata": {},
   "source": [
    "### Choosing the right run type\n",
    "\n",
    "> These are only advices and it will dependend on the graph you are running and its purpose (if development, production big amount of data, production speed and small amount of data, etc).\n",
    "\n",
    "\n",
    "1. **Default (as implemented)**\n",
    "\n",
    "* Running pipelines\n",
    "* Big volume of data\n",
    "\n",
    "2. **Providing an existent `pyspark` dataframe as input**\n",
    "\n",
    "* Debugging failed pipelines\n",
    "* Last check before finishing development\n",
    "\n",
    "3. **Providing `pandas` dataframe as input**\n",
    "\n",
    "* Developing pipelines\n",
    "* Extract a small set of data into a Pandas dataframe will be faster to run the pipeline multiple times during development\n",
    "\n",
    "4. **`pandas_on_spark` nodes as `pandas`**\n",
    "\n",
    "* Pipelines with small amount of data\n",
    "\n",
    "5. **`pandas_on_spark` nodes as `pandas` + provided `pyspark` dataframe as input**\n",
    "\n",
    "* Pipelines with small amount of data\n",
    "\n",
    "6. **`pandas_on_spark` nodes as `pandas` + provided `pandas` dataframe as input**\n",
    "\n",
    "* When speed is important\n",
    "* Small amount of data\n",
    "* On demand feature generation\n",
    "* Within APIs (running pipeline with data sent in requests)\n",
    "* Unit tests (will avoid use of a spark session)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
