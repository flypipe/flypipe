{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d12cf88-3ba0-4686-ae9f-08f47d073e50",
   "metadata": {},
   "source": [
    "## Multi node type Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f7c8c16-c3b3-4ff4-813b-45615a01e911",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Dummy raw data\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241m.\u001b[39mcreateDataFrame(\n\u001b[1;32m      4\u001b[0m     schema\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_fruit\u001b[39m\u001b[38;5;124m\"\u001b[39m,),\n\u001b[1;32m      5\u001b[0m     data\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m      6\u001b[0m         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mORANGE\u001b[39m\u001b[38;5;124m\"\u001b[39m,),\n\u001b[1;32m      7\u001b[0m         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWATERMELON\u001b[39m\u001b[38;5;124m\"\u001b[39m,),\n\u001b[1;32m      8\u001b[0m         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLEMON\u001b[39m\u001b[38;5;124m\"\u001b[39m,),\n\u001b[1;32m      9\u001b[0m     ]\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     11\u001b[0m df\u001b[38;5;241m.\u001b[39mcreateOrReplaceTempView(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m display(df)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "#Dummy raw data\n",
    "\n",
    "df = spark.createDataFrame(\n",
    "    schema=(\"_fruit\",),\n",
    "    data=[\n",
    "        (\"ORANGE\",),\n",
    "        (\"WATERMELON\",),\n",
    "        (\"LEMON\",),\n",
    "    ]\n",
    ")\n",
    "df.createOrReplaceTempView(\"table\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f215ef5-c0dd-474b-a523-04015f132c6d",
   "metadata": {},
   "source": [
    "### Define the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb85a68-644f-4e82-9b69-89875210f6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flypipe import node\n",
    "from flypipe.datasource.spark import Spark\n",
    "from flypipe.schema import Schema, Column\n",
    "from flypipe.schema.types import String\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "\n",
    "@node(\n",
    "    type=\"pandas_on_spark\",\n",
    "    dependencies=[\n",
    "        Spark(\"table\").select(\"_fruit\").alias(\"df\")\n",
    "    ],\n",
    "    output=Schema(\n",
    "     Column(\"fruit\", String(), \"fruit description\"),\n",
    "    )\n",
    ")\n",
    "def rename_clean(df):\n",
    "    df = df.rename(columns={'_fruit': 'fruit'})\n",
    "    df['fruit'] = df['fruit'].str.lower()\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "@node(\n",
    "    type=\"pandas_on_spark\",\n",
    "    dependencies=[\n",
    "       rename_clean.select(\"fruit\").alias(\"df\")\n",
    "    ],\n",
    "    output=Schema(\n",
    "        rename_clean.output.get(\"fruit\"),\n",
    "        Column(\"color\", String(), \"color of the fruit\"),\n",
    "    )\n",
    ")\n",
    "def color(df):\n",
    "\n",
    "    replacements = {\n",
    "        \"orange\": \"orange\",\n",
    "        \"watermelon\": \"red\",\n",
    "        \"lemon\": \"yellow\",\n",
    "    }\n",
    "    df['color'] = df['fruit']\n",
    "    df = df.replace({'color': replacements})\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "@node(\n",
    "    type=\"pandas_on_spark\",\n",
    "    dependencies=[\n",
    "       rename_clean.select(\"fruit\").alias(\"df\")\n",
    "    ],\n",
    "    output=Schema(\n",
    "        rename_clean.output.get(\"fruit\"),\n",
    "        Column(\"category\", String(), \"category of the fruit\"),\n",
    "    )\n",
    ")\n",
    "def category(df):\n",
    "\n",
    "    replacements = {\n",
    "        \"orange\": \"citric\",\n",
    "        \"watermelon\": \"sweet\",\n",
    "        \"lemon\": \"citric\",\n",
    "    }\n",
    "    \n",
    "    df['category'] = df['fruit']\n",
    "    df = df.replace({'category': replacements})\n",
    "    return df\n",
    "\n",
    "\n",
    "@node(\n",
    "    type=\"pandas\",\n",
    "    dependencies=[\n",
    "       color.select(\"fruit\", \"color\"),\n",
    "       category.select(\"fruit\", \"category\")\n",
    "    ],\n",
    "    output=Schema(\n",
    "        color.output.get(\"fruit\"),\n",
    "        color.output.get(\"color\"),\n",
    "        category.output.get(\"category\"),\n",
    "    )\n",
    ")\n",
    "def fruits(color, category):\n",
    "    return color.merge(category, on=\"fruit\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c00ac07-7993-4bf2-ba37-6a7aaa154dfc",
   "metadata": {},
   "source": [
    "The code above created a graph with 3 types of nodes\n",
    "\n",
    "* table: `pyspark` node\n",
    "* clean: `pandas_on_spark` node\n",
    "* color: `pandas_on_spark` node\n",
    "* category: `pandas` node\n",
    "\n",
    "As you can see the graph bellow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ac5192-aa18-4c81-8f3b-32bf554b999c",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_width=600\n",
    "html_height=300\n",
    "displayHTML(fruits.html(width=html_width, height=html_height))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1ac2a1-dab5-4a22-a965-376271a44d97",
   "metadata": {},
   "source": [
    "When running this graph the following processes will be executed:\n",
    "\n",
    "1. spark will query the table and select the columns specified in node `table`\n",
    "2. before running node `rename_clean`, flypipe will convert the ouput *pyspark* dataframe from node `table` to a *pandas_on_spark* dataframe\n",
    "3. node `rename_clean` is processed\n",
    "4. nodes `color` and `category` will be processed using the output *pandas_on_spark* dataframe output by node `rename_clean`\n",
    "5. once nodes `color` and `category` are processed, each dataframe is converted to `pandas` dataframe as node `fruits` is of the type *pandas*\n",
    "6. node `fruits` is processed and its dataframe output is returned\n",
    "\n",
    "Flypipe managages all these sequences and transformations for the user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf85a420-d948-4579-a02f-927647a5be88",
   "metadata": {},
   "source": [
    "### Advantages of mixed node types pipelines\n",
    "\n",
    "As *Flypipe* can manage different types of nodes, it allows:\n",
    "\n",
    "* unifies different teams pipelines end-to-end (data -> feture engineering -> modelling -> inference -> ...) [^1]\n",
    "* can lead to much faster results if running nodes `pandas_on_spark` as `pandas`\n",
    "* same pipeline can be used within APIS to run on the fly transformations\n",
    "\n",
    "[^1]: Different teams can use different syntaxes, i.e. `pyspark` is commnly used by data engineers, and `pandas` is commonly used by machine learning and data science teams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4c82fc-bd69-4d87-9dcc-de30b5fb9396",
   "metadata": {},
   "source": [
    "### Running Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a435a80-5d8c-4239-961e-13a675c9cb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "results = pd.DataFrame(columns=['experiment', 'running_time_ms'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a830ef5-c20a-4a96-aaed-1c1d8c12b601",
   "metadata": {},
   "source": [
    "#### Default (as implemented)\n",
    "\n",
    "```python\n",
    "\n",
    "fruits.run(spark)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0325d2a8-f457-4dc1-97e2-9601a513b423",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = \"Default (as implemented)\"\n",
    "result = %timeit -o fruits.run(spark)\n",
    "results.loc[results.shape[0]] = [experiment, result.average]\n",
    "\n",
    "displayHTML(fruits.html(width=html_width, height=html_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b8d701-4945-4c54-a190-90d68b967122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88379c4e-d9da-407a-82f7-542125750ea1",
   "metadata": {},
   "source": [
    "#### Default (as implemented) + provided `pyspark` dataframe as input\n",
    "\n",
    "```python\n",
    "fruit_table_df = spark.createDataFrame(\n",
    "    pd.DataFrame(data={\"_fruit\": [\"ORANGE\", \"WATERMELON\", \"LEMON\"]})\n",
    ")\n",
    "\n",
    "fruits.run(inputs={ \n",
    "    Spark(\"table\"): fruit_table_df \n",
    "})\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89cdc66-abb1-4911-b773-01fc3ee77bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = \"Default (as implemented) + provided `pyspark` dataframe as input\"\n",
    "print(experiment)\n",
    "fruit_table_df = spark.createDataFrame(pd.DataFrame(data={\"_fruit\": [\"ORANGE\", \"WATERMELON\", \"LEMON\"]}))\n",
    "result = %timeit -o fruits.run(inputs={ Spark(\"table\"): fruit_table_df })\n",
    "results.loc[results.shape[0]] = [experiment, result.average]\n",
    "\n",
    "displayHTML(fruits.html(inputs={ Spark(\"table\"): fruit_table_df }, width=html_width, height=html_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c18358f-603a-463b-943f-44afd54af173",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fba18a06-10db-45a4-9af9-f0e8d7a29839",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Default (as implemented) + provided `pandas` dataframe as input\n",
    "\n",
    "```python\n",
    "fruit_table_df = pd.DataFrame(data={\"_fruit\": [\"ORANGE\", \"WATERMELON\", \"LEMON\"]})\n",
    "\n",
    "fruits.run(inputs={ \n",
    "    Spark(\"table\"): fruit_table_df \n",
    "})\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f040e0f-4c77-4893-aff0-384bfcd3a13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running pandas_on_spark nodes as pandas and with provided input\n",
    "fruit_table_df = pd.DataFrame(data={\"_fruit\": [\"ORANGE\", \"WATERMELON\", \"LEMON\"]})\n",
    "\n",
    "experiment = \"Default (as implemented) + provided `pandas` dataframe as input\"\n",
    "print(experiment)\n",
    "result = %timeit -o fruits.run(spark, inputs={ Spark(\"table\"): fruit_table_df })\n",
    "results.loc[results.shape[0]] = [experiment, result.average]\n",
    "\n",
    "displayHTML(fruits.html(inputs={ Spark(\"table\"): fruit_table_df }, width=html_width, height=html_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b142af60-f733-41c0-a94f-a0037d0ed832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9391477-1649-4fdf-b2fe-e773d6460ae6",
   "metadata": {},
   "source": [
    "#### `pandas_on_spark` nodes as `pandas`\n",
    "\n",
    "```python\n",
    "\n",
    "fruits.run(\n",
    "    spark, \n",
    "    pandas_on_spark_use_pandas=True\n",
    ")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64eca480-75a5-4a53-a109-d17b83e11d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = \"`pandas_on_spark` nodes as `pandas`\"\n",
    "print(experiment)\n",
    "result = %timeit -o fruits.run(spark, pandas_on_spark_use_pandas=True)\n",
    "results.loc[results.shape[0]] = [experiment, result.average]\n",
    "\n",
    "displayHTML(fruits.html(pandas_on_spark_use_pandas=True, width=html_width, height=html_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78bb2b3-fa9c-4091-9f77-26f7f0ed82a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6775020f-ff70-4c3c-bf80-c169349bcf31",
   "metadata": {},
   "source": [
    "#### `pandas_on_spark` nodes as `pandas` + provided `pyspark` dataframe as input\n",
    "\n",
    "```python\n",
    "fruit_table_df = spark.createDataFrame(\n",
    "    pd.DataFrame(data={\"_fruit\": [\"ORANGE\", \"WATERMELON\", \"LEMON\"]})\n",
    ")\n",
    "\n",
    "fruits.run(\n",
    "    pandas_on_spark_use_pandas=True, \n",
    "    inputs={ \n",
    "        Spark(\"table\"): fruit_table_df \n",
    "    }\n",
    ")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d65c88-23d5-4d91-96f9-a593cb53cb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = \"`pandas_on_spark` nodes as `pandas` + provided `pyspark` dataframe as input\"\n",
    "print(experiment)\n",
    "fruit_table_df = spark.createDataFrame(pd.DataFrame(data={\"_fruit\": [\"ORANGE\", \"WATERMELON\", \"LEMON\"]}))\n",
    "result = %timeit -o fruits.run(pandas_on_spark_use_pandas=True, inputs={ Spark(\"table\"): fruit_table_df })\n",
    "results.loc[results.shape[0]] = [experiment, result.average]\n",
    "\n",
    "displayHTML(fruits.html(inputs={ Spark(\"table\"): fruit_table_df }, pandas_on_spark_use_pandas=True, width=html_width, height=html_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b63b4e6-0b1b-491b-b808-902a69adcc9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2836670-7ecd-4383-bae0-dacf819e3d5a",
   "metadata": {},
   "source": [
    "#### `pandas_on_spark` nodes as `pandas` + provided `pandas` dataframe as input\n",
    "\n",
    "```python\n",
    "fruit_table_df = pd.DataFrame(data={\"_fruit\": [\"ORANGE\", \"WATERMELON\", \"LEMON\"]})\n",
    "\n",
    "fruits.run(\n",
    "    pandas_on_spark_use_pandas=True, \n",
    "    inputs={ \n",
    "        Spark(\"table\"): fruit_table_df \n",
    "    }\n",
    ")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6455e9-9e94-4397-9649-46bb0bf11099",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = \"`pandas_on_spark` nodes as `pandas` + provided `pandas` dataframe as input\"\n",
    "print(experiment)\n",
    "fruit_table_df = pd.DataFrame(data={\"_fruit\": [\"ORANGE\", \"WATERMELON\", \"LEMON\"]})\n",
    "result = %timeit -o fruits.run(pandas_on_spark_use_pandas=True, inputs={ Spark(\"table\"): fruit_table_df })\n",
    "results.loc[results.shape[0]] = [experiment, result.average]\n",
    "\n",
    "displayHTML(fruits.html(inputs={ Spark(\"table\"): fruit_table_df }, pandas_on_spark_use_pandas=True, width=html_width, height=html_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5c9067-c117-4b02-9f37-128fbd2a7de2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc63f6e-95da-470f-a0ec-72d3cf972b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import wrap\n",
    "results['experiment'] = results['experiment'].apply(lambda x: '\\n'.join(wrap(x, 20)))\n",
    "results['running_time_ms'] = results['running_time_ms'] * 1000\n",
    "results['running_time_ms'] = round(results['running_time_ms'], 1)\n",
    "# results = results.sort_values('running_time_ms', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c1f8a3-6a2a-4671-b184-396ce84154db",
   "metadata": {},
   "source": [
    "#### Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11dcf62-a1bd-4a01-809d-f37a277d4b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "fig, ax = plt.subplots(figsize=(16, 4))\n",
    "pal = sns.color_palette(\"Blues_d\", len(results))\n",
    "barchart = (\n",
    "    sns.barplot(x=results['experiment'], \n",
    "                y=results['running_time_ms'], \n",
    "                palette=np.array(pal[::-1]),\n",
    "                ax=ax)\n",
    "                .set(title='Running time (ms) by different ways of running the graph')\n",
    ")\n",
    "_ = ax.bar_label(ax.containers[0], fmt='%.1fms')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818f251d-a989-4921-872e-1f3098628551",
   "metadata": {},
   "source": [
    "### Choosing the right run type\n",
    "\n",
    "```{note}\n",
    "\n",
    "These are only advices and it will dependend on the graph you are running and its purpose (if development, production big amount of data, production speed and small amount of data, etc).\n",
    "\n",
    "```\n",
    "\n",
    "**Default (as implemented)**\n",
    "\n",
    "* Running pipelines\n",
    "* Big volume of data\n",
    "\n",
    "**Default (as implemented) + provided `pyspark` dataframe as input**\n",
    "\n",
    "* Debugging failed pipelines\n",
    "* Last check before finishing development\n",
    "\n",
    "**Default (as implemented) + provided `pandas` dataframe as input**\n",
    "\n",
    "* Developing pipelines\n",
    "* Extract a small set of data into a Pandas dataframe will be faster to run the pipeline multiple times during development\n",
    "\n",
    "**pandas_on_spark nodes as pandas**\n",
    "\n",
    "* Pipelines with small amount of data\n",
    "\n",
    "**pandas_on_spark nodes as pandas + provided pyspark dataframe as input**\n",
    "\n",
    "* Pipelines with small amount of data\n",
    "\n",
    "**pandas_on_spark nodes as pandas + provided pandas dataframe as input**\n",
    "\n",
    "* When speed is important\n",
    "* Small amount of data\n",
    "* On demand feature generation\n",
    "* Within APIs (running pipeline with data sent in requests)\n",
    "* Unit tests (will avoid use of a spark session)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
